{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, mean_absolute_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def timeit(method):\n",
    "    '''A time decorator to time other functions.'''\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "        if 'log_time' in kw:\n",
    "            name = kw.get('log_name', method.__name__.upper())\n",
    "            kw['log_time'][name] = int((te - ts) * 1000)\n",
    "        else:\n",
    "            print ('%r  %2.2f ms' %(method.__name__, (te - ts) * 1000))\n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Function\n",
    "Basic function that reads in the weather csv, formats it and merges it with supplied data, returning the merged datframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I cleaned this function a little bit. -Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weatherInfo(data):\n",
    "    '''Add weather information (temp, precipitation) to the dataframe.'''\n",
    "    \n",
    "    weather = pd.read_csv('CleanedWeather2016_17C.csv',index_col=0)\n",
    "    \n",
    "    data.dayofservice = data.dayofservice.astype('datetime64[ns]')\n",
    "    data['datetime'] = data.dayofservice + pd.to_timedelta(data.actual_arr,unit='s')\n",
    "    data['weekday'] = data.dayofservice.dt.dayofweek\n",
    "    data = data.sort_values('datetime')\n",
    "    #data = data.reset_index()\n",
    "    data[['tripid','progrnumber']] = data[['tripid','progrnumber']].astype('int')\n",
    "    df = pd.merge_asof(data,weather,on='datetime',tolerance=pd.Timedelta('1h'))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train&Predict Class\n",
    "\n",
    "Class that reads in a cleaned df a set of xCols and a target feature. Has methods for MSE, MAE and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTrainPredict:\n",
    "    \n",
    "    def __init__ (self, df, xCol, y, name=\"\"):\n",
    "        self.df = df\n",
    "        self.xCol = xCol\n",
    "        self.y = y\n",
    "        self.__split = int(self.df.shape[0]*0.7)\n",
    "        self.__X = pd.get_dummies(self.df[self.Xcol],drop_first=True)\n",
    "        self.__xTrain, self.__xTest = self.__X[:self.__split], self.__X[self.__split:]\n",
    "        self.__yTrain, self.__yTest = self.df[self.y][:self.__split], self.df[self.y][self.__split:]\n",
    "        self.__regr = linear_model.LinearRegression()\n",
    "        if name == \"\"\n",
    "            pass\n",
    "        else:\n",
    "            with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "                pickle.dump(self.__regr, f, pickle.HIGHEST_PROTOCOL)\n",
    "        self.__regr.fit(self.__xTrain, self.__yTrain)\n",
    "        self.yPred = self.__regr.predict(self.__xTest)\n",
    "        \n",
    "    def mSqErr(self):\n",
    "        return mean_squared_error(self.__yTest,self.yPred)\n",
    "        \n",
    "    def mAbsErr(self):\n",
    "        return mean_absolute_error(self.__yTest,self.yPred)\n",
    "    \n",
    "    def varScore(self):\n",
    "        return r2_score(self.__yTest,self.yPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Dfs\n",
    "\n",
    "Some fucntions that clean dfs and adds features such as weekday and month integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def dateManipulations(df, dateCol, arrCol, m=False, d=False, weekendSplit=False):\n",
    "def dateManipulations(df, dateCol='dayofservice', d=False, weekendSplit=False):\n",
    "    #Suggest: add this default value here â†‘\n",
    "    \n",
    "    \n",
    "    # ? Duplicate with the weatherInfo function here...\n",
    "    #df.dateCol = df.dateCol.astype('datetime64[ns]')\n",
    "    #df['datetime'] = df.dateCol + pd.to_timedelta(df.arrCol, unit = 's')\n",
    "    # ?\n",
    "    #Suggest to call weatherInfo instead:\n",
    "    df = weatherInfo(df)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    #We don't use month as a feature anymore, this block can be deleted.\n",
    "    \n",
    "    #if m == False:\n",
    "    #Suggest change to:\n",
    "    if not m:\n",
    "        pass\n",
    "    \n",
    "    #Suggest change to:\n",
    "    elif m:\n",
    "    #elif m == True:\n",
    "        df['month'] = df.dateCol.map(lambda x: x.month)\n",
    "    else:\n",
    "        return 'Error in month input, must be True or False!'\n",
    "    '''\n",
    "    \n",
    "    #same as above.\n",
    "    #if d == False:\n",
    "    if not d:\n",
    "        pass\n",
    "    \n",
    "    #elif d == True:\n",
    "    elif d:\n",
    "        df['weekday'] = df.dateCol.dt.dayofweek\n",
    "    else:\n",
    "        return 'Error in day input, must be True or False!'\n",
    "    \n",
    "    #suggest change to:\n",
    "    if weekendSplit and d:\n",
    "    #if weekendSplit == True && d == True:\n",
    "        \n",
    "        #df['m2f'] = np.where((df.weekday ==0) & (df.weekday ==1) & (df.weekday ==2) & (df.weekday ==3) & (df.weekday ==4),1,0)\n",
    "        #Suggest change to:\n",
    "        df['m2f'] = np.where(df.weekday <= 4, 1,0)\n",
    "        df['sat'] = np.where((df.weekday == 5),1,0)\n",
    "        \n",
    "    #same above\n",
    "    elif not weekendSplit:\n",
    "    #elif weekendSplit == False:\n",
    "        pass\n",
    "    #elif weekendSplit == True && d == False:\n",
    "    elif weekendSplit and not d:\n",
    "        return 'Error, must have weekday column for weekend split'\n",
    "    else:\n",
    "        return 'Error in weekend split input, must be True or False!'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPeakHours(df, timeOfDayCol):\n",
    "    df['em'] = np.where((df[timeOfDayCol] > 14400) & (df[timeOfDayCol] <=  25200),1,0)\n",
    "    df['mp'] = np.where((df[timeOfDayCol] > 25200) & (df[timeOfDayCol] <=  36000),1,0)\n",
    "    df['lm'] = np.where((df[timeOfDayCol] > 36000) & (df[timeOfDayCol] <=  46800),1,0)\n",
    "    df['md'] = np.where((df[timeOfDayCol] > 46800) & (df[timeOfDayCol] <=  47600),1,0)\n",
    "    df['ap'] = np.where((df[timeOfDayCol] > 47600) & (df[timeOfDayCol] <=  68400),1,0)\n",
    "    df['ev'] = np.where((df[timeOfDayCol] > 68400) & (df[timeOfDayCol] <=  79200),1,0)\n",
    "    df['ln'] = np.where((df[timeOfDayCol] > 79200) & (df[timeOfDayCol] <=  90000),1,0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route Manipulation functions\n",
    "\n",
    "Functions that uses stop_times.txt to generate features and a route Dictionary that will be used with model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some of the work is once off, I suggest do it once not do it everytime we load in the txt.\n",
    "import pandas as pd\n",
    "stoptime = pd.read_csv('stop_times.txt')\n",
    "#Only look at the rows for certain route.\n",
    "stoptime['line'] = stoptime.trip_id.str.split('-').str[1]\n",
    "stoptime = stoptime[stoptime.stop_id.str.contains(':') == False]\n",
    "stoptime['stopid'] = stoptime.stop_id.str.slice(8,)\n",
    "stoptime.stopid = stoptime['stopid'].astype('int64')\n",
    "stoptime.to_csv('stop_timesC',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_headsign</th>\n",
       "      <th>pickup_type</th>\n",
       "      <th>drop_off_type</th>\n",
       "      <th>shape_dist_traveled</th>\n",
       "      <th>line</th>\n",
       "      <th>stopid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3643.y102m.60-1-d12-1.1.O</td>\n",
       "      <td>15:40:00</td>\n",
       "      <td>15:40:00</td>\n",
       "      <td>8240DB000226</td>\n",
       "      <td>1</td>\n",
       "      <td>Sandymount</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3643.y102m.60-1-d12-1.1.O</td>\n",
       "      <td>15:40:47</td>\n",
       "      <td>15:40:47</td>\n",
       "      <td>8240DB000228</td>\n",
       "      <td>2</td>\n",
       "      <td>Sandymount</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>261.136188</td>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3643.y102m.60-1-d12-1.1.O</td>\n",
       "      <td>15:41:26</td>\n",
       "      <td>15:41:26</td>\n",
       "      <td>8240DB000229</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandymount</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>484.925289</td>\n",
       "      <td>1</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3643.y102m.60-1-d12-1.1.O</td>\n",
       "      <td>15:42:30</td>\n",
       "      <td>15:42:30</td>\n",
       "      <td>8240DB000227</td>\n",
       "      <td>4</td>\n",
       "      <td>Sandymount</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>836.995679</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3643.y102m.60-1-d12-1.1.O</td>\n",
       "      <td>15:43:09</td>\n",
       "      <td>15:43:09</td>\n",
       "      <td>8240DB000230</td>\n",
       "      <td>5</td>\n",
       "      <td>Sandymount</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1066.461783</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     trip_id arrival_time departure_time       stop_id  \\\n",
       "0  3643.y102m.60-1-d12-1.1.O     15:40:00       15:40:00  8240DB000226   \n",
       "1  3643.y102m.60-1-d12-1.1.O     15:40:47       15:40:47  8240DB000228   \n",
       "2  3643.y102m.60-1-d12-1.1.O     15:41:26       15:41:26  8240DB000229   \n",
       "3  3643.y102m.60-1-d12-1.1.O     15:42:30       15:42:30  8240DB000227   \n",
       "4  3643.y102m.60-1-d12-1.1.O     15:43:09       15:43:09  8240DB000230   \n",
       "\n",
       "   stop_sequence stop_headsign  pickup_type  drop_off_type  \\\n",
       "0              1    Sandymount            0              0   \n",
       "1              2    Sandymount            0              0   \n",
       "2              3    Sandymount            0              0   \n",
       "3              4    Sandymount            0              0   \n",
       "4              5    Sandymount            0              0   \n",
       "\n",
       "   shape_dist_traveled line  stopid  \n",
       "0             0.000000    1     226  \n",
       "1           261.136188    1     228  \n",
       "2           484.925289    1     229  \n",
       "3           836.995679    1     227  \n",
       "4          1066.461783    1     230  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoptime = pd.read_csv('stop_timesC')\n",
    "#stoptime.dtypes\n",
    "stoptime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_headsign</th>\n",
       "      <th>pickup_type</th>\n",
       "      <th>drop_off_type</th>\n",
       "      <th>shape_dist_traveled</th>\n",
       "      <th>line</th>\n",
       "      <th>stopid</th>\n",
       "      <th>tripmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3643.y102m.60-1-d12-1.1.O</td>\n",
       "      <td>15:40:00</td>\n",
       "      <td>15:40:00</td>\n",
       "      <td>8240DB000226</td>\n",
       "      <td>1</td>\n",
       "      <td>Sandymount</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3643.y102m.60-1-d12-1.1.O</td>\n",
       "      <td>15:40:47</td>\n",
       "      <td>15:40:47</td>\n",
       "      <td>8240DB000228</td>\n",
       "      <td>2</td>\n",
       "      <td>Sandymount</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>261.136188</td>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3643.y102m.60-1-d12-1.1.O</td>\n",
       "      <td>15:41:26</td>\n",
       "      <td>15:41:26</td>\n",
       "      <td>8240DB000229</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandymount</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>484.925289</td>\n",
       "      <td>1</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3643.y102m.60-1-d12-1.1.O</td>\n",
       "      <td>15:42:30</td>\n",
       "      <td>15:42:30</td>\n",
       "      <td>8240DB000227</td>\n",
       "      <td>4</td>\n",
       "      <td>Sandymount</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>836.995679</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3643.y102m.60-1-d12-1.1.O</td>\n",
       "      <td>15:43:09</td>\n",
       "      <td>15:43:09</td>\n",
       "      <td>8240DB000230</td>\n",
       "      <td>5</td>\n",
       "      <td>Sandymount</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1066.461783</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     trip_id arrival_time departure_time       stop_id  \\\n",
       "0  3643.y102m.60-1-d12-1.1.O     15:40:00       15:40:00  8240DB000226   \n",
       "1  3643.y102m.60-1-d12-1.1.O     15:40:47       15:40:47  8240DB000228   \n",
       "2  3643.y102m.60-1-d12-1.1.O     15:41:26       15:41:26  8240DB000229   \n",
       "3  3643.y102m.60-1-d12-1.1.O     15:42:30       15:42:30  8240DB000227   \n",
       "4  3643.y102m.60-1-d12-1.1.O     15:43:09       15:43:09  8240DB000230   \n",
       "\n",
       "   stop_sequence stop_headsign  pickup_type  drop_off_type  \\\n",
       "0              1    Sandymount            0              0   \n",
       "1              2    Sandymount            0              0   \n",
       "2              3    Sandymount            0              0   \n",
       "3              4    Sandymount            0              0   \n",
       "4              5    Sandymount            0              0   \n",
       "\n",
       "   shape_dist_traveled line  stopid tripmark  \n",
       "0             0.000000    1     226        1  \n",
       "1           261.136188    1     228        1  \n",
       "2           484.925289    1     229        1  \n",
       "3           836.995679    1     227        1  \n",
       "4          1066.461783    1     230        1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoptime['tripmark'] = stoptime.trip_id.str.split('.').str[3]\n",
    "stoptime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoptime[['stop_sequence','stop_headsign','shape_dist_traveled','line','stopid','tripmark']].drop_duplicates().to_csv('stop_timeCC',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I notice a situation that you cannot just use get unique to get all the unique route. This is because there are more than one\n",
    "route for a bus line + direction. E.g.:\n",
    "39aO has three combination, \n",
    "1. start from UCD(767), go to Ongar\n",
    "2. start from UCD(767), go to Aston\n",
    "3. start from Aston(328), go to Ongar.\n",
    "Base on this kind of situation, I suggest we name route as 39a767Ongar (busline+startstopid+destinationStop).\n",
    "This will guarantee we have all the routes and it would be clean and without dupilication.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def append_obj(obj,name):\n",
    "    with open('obj/'+ name + '.pkl', 'ab') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{767: 0.0,\n",
       " 768: 657.287066064875,\n",
       " 769: 985.330520927881,\n",
       " 770: 1429.24894221461,\n",
       " 771: 1620.44696377974,\n",
       " 772: 2127.48709498295,\n",
       " 773: 3434.8578642479997,\n",
       " 774: 3677.18821727873,\n",
       " 775: 4001.74363072419,\n",
       " 776: 4285.13185337461,\n",
       " 777: 4493.83259606615,\n",
       " 779: 4740.48732233394,\n",
       " 780: 5009.04830237385,\n",
       " 781: 5193.6587029476,\n",
       " 782: 5357.09815442135,\n",
       " 783: 5606.069766801032,\n",
       " 784: 5776.637949866071,\n",
       " 785: 6055.606335357479,\n",
       " 786: 6545.589502681712,\n",
       " 793: 7269.64182312836,\n",
       " 7586: 7835.15763393275,\n",
       " 7587: 8467.10980025078,\n",
       " 7588: 8530.04627616102,\n",
       " 328: 9243.322928124291,\n",
       " 1443: 9826.568859010358,\n",
       " 1444: 10107.2418629801,\n",
       " 1445: 10417.1497368751,\n",
       " 1647: 10939.5178555804,\n",
       " 1648: 11272.5213698264,\n",
       " 1649: 11469.3056185517,\n",
       " 1911: 11995.4996735001,\n",
       " 1913: 12337.7290265695,\n",
       " 1914: 12592.8159362723,\n",
       " 1805: 12806.0519246444,\n",
       " 1806: 13196.947965981299,\n",
       " 1660: 13713.2410577792,\n",
       " 1661: 13997.7195279663,\n",
       " 1662: 14322.374320031799,\n",
       " 1664: 14788.0353517777,\n",
       " 1665: 15079.2139210518,\n",
       " 1666: 15297.9786348426,\n",
       " 1807: 15967.1810641978,\n",
       " 7167: 16369.8533845337,\n",
       " 1808: 17103.152811295702,\n",
       " 7389: 18513.6157131016,\n",
       " 7025: 20668.56662585,\n",
       " 4464: 21247.637917564498,\n",
       " 1869: 21507.9762408622,\n",
       " 1870: 21728.6060840384,\n",
       " 1871: 21997.7051787869,\n",
       " 1872: 22281.5037947158,\n",
       " 1873: 22612.4879650431,\n",
       " 1874: 22895.4121631934,\n",
       " 1875: 23138.8029119334,\n",
       " 1876: 23387.224631250898,\n",
       " 1877: 23746.9918188,\n",
       " 1878: 24123.2834825881,\n",
       " 1879: 24537.666585506602,\n",
       " 1899: 24969.4769196035,\n",
       " 6107: 25191.7656265229,\n",
       " 6108: 25502.7720573246,\n",
       " 6109: 25868.320069861602,\n",
       " 6110: 26456.658753571093,\n",
       " 7020: 26997.648635589303,\n",
       " 7029: 27197.0086661429,\n",
       " 7038: 27567.268713262998,\n",
       " 7011: 28078.4858492885,\n",
       " 2171: 28824.5486652296,\n",
       " 7160: 28975.920015846,\n",
       " 7047: 29493.627107084103,\n",
       " 7161: 29829.2320531325,\n",
       " 7162: 30162.2693348186}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = load_obj('stopDicts/39A_767_ Ongar')\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the discussion above, I changed this function into a function that run once and split all the routes into pickle file\n",
    "# for later consideration:\n",
    "#https://stackoverflow.com/questions/16497115/python-pickle-vs-sql-efficiency\n",
    "#security issue? efficiency issue?...\n",
    "@timeit\n",
    "def getStops(file):\n",
    "    \n",
    "    '''get stops for a certain route from GTFS file.'''\n",
    "    \n",
    "    stoptime = pd.read_csv(file)\n",
    "    '''\n",
    "    #stoptime['line'] = stoptime.trip_id.str.split('-').str[1]\n",
    "    #stoptime = stoptime[stoptime.stop_id.str.contains(':') == False]\n",
    "    #stoptime['stopid'] = stoptime.stop_id.str.slice(8,)\n",
    "    #stoptime.stopid = stoptime['stopid'].astype('int64')\n",
    "    \n",
    "    if outbound == True:\n",
    "        routeDf = stoptime.loc[(stoptime.line == route) & (stoptime.trip_id.str.split('.').str[4]=='O')]\n",
    "    elif outbound == False:\n",
    "        routeDf = stoptime.loc[(stoptime.line == route) & (stoptime.trip_id.str.split('.').str[4]=='I')]\n",
    "    else:\n",
    "        return 'Error outbound must be True or False!'\n",
    "    \n",
    "    #Now there are many duplicate in the df, get unique.\n",
    "    \n",
    "    return routeDf[['stop_sequence','shape_dist_traveled', 'stopid']]\n",
    "    \n",
    "    header = ['stop_sequence','stop_headsign','shape_dist_traveled','line','stopid','tripmark']\n",
    "    '''\n",
    "    for line in stoptime.line.unique():\n",
    "        for tm in stoptime.tripmark.unique():\n",
    "            df = stoptime.loc[(stoptime.line == line) & (stoptime.tripmark == tm)]\n",
    "            #print(df)\n",
    "            if not df.empty and not df.loc[df.stop_sequence==1,'stopid'].empty:\n",
    "                #IndexError: index 0 is out of bounds for axis 0 with size 0\n",
    "                start = str(df.loc[df.stop_sequence==1,'stopid'].values[0]).strip()\n",
    "                dest = str(df.loc[df.stop_sequence==1,'stop_headsign'].values[0]).strip()\n",
    "                save_obj(df[['stopid','shape_dist_traveled']].set_index('stopid')['shape_dist_traveled'].to_dict(), \\\n",
    "                         'stopDicts/'+str(line)+'_'+start+'_'+ dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'getStops'  355207.28 ms\n"
     ]
    }
   ],
   "source": [
    "getStops('stop_timeCC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStopDict(routeDf, name):\n",
    "    stops = routeDf[['stop_sequence','stopid']]\n",
    "    stops = stops.reset_index(drop = True)\n",
    "    stops = stops.sort_values('stop_sequence')\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(stops.stopid.tolist(), f, pickle.HIGHEST_PROTOCOL)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkstopSeq(routeDf):\n",
    "    if routeDf.stopSeq.iloc[0] != 1:\n",
    "        print('Starting stop is not 1')\n",
    "        return False\n",
    "    else:\n",
    "        for i in routeDf.stopSeq:\n",
    "            if routeDf.stopSeq.iloc[i+1] - routeDf.stopSeq.iloc[i] == 1:\n",
    "                pass\n",
    "                if routeDf.stopSeq.iloc[i+1] == routeDf.stopSeq.iloc[-1]:\n",
    "                    break\n",
    "            else:\n",
    "                return False\n",
    "            if routeDf.stopSeq.is_monotonic_increasing == True:\n",
    "                return True\n",
    "            elif routeDf.stopSeq.is_monotonic_increasing == False:\n",
    "                return False\n",
    "            else:\n",
    "                return 'Error in monotonic method'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
