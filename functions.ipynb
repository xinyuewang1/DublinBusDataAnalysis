{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def timeit(method):\n",
    "    '''A time decorator to time other functions.'''\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "        if 'log_time' in kw:\n",
    "            name = kw.get('log_name', method.__name__.upper())\n",
    "            kw['log_time'][name] = int((te - ts) * 1000)\n",
    "        else:\n",
    "            print ('%r  %2.2f ms' %(method.__name__, (te - ts) * 1000))\n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@timeit\n",
    "def tableClean(file):\n",
    "    '''Specifically build to clean leavetime table. Drop useless rows and columns to minimize the size of the file.'''\n",
    "    dropCols = ['datasource','passengers','passengersin','passengersout','distance','note','lastupdate','justificationid',\n",
    "                'plannedtime_dep', 'vehicleid']\n",
    "    df = pd.DataFrame()\n",
    "    for chunk in pd.read_csv(file, sep=';', chunksize=10000):\n",
    "        chunk = chunk.drop(dropCols,1)\n",
    "        chunk = chunk.drop(chunk[chunk.suppressed >= 0].index)\n",
    "        chunk = chunk.drop(['suppressed'],1)\n",
    "        chunk['dayofservice'] = pd.to_datetime(chunk['dayofservice'], format='%d-%b-%y %H:%M:%S')\n",
    "        chunk = chunk.rename({'plannedtime_arr' : 'plannedtime'}, axis=1)\n",
    "        #leavetimesOf39aSample = pd.concat([leavetimesOf39aSample,chunk.loc[chunk['tripid'] == trip]])\n",
    "        df = pd.concat([df,chunk])\n",
    "    df.to_csv(file+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tableClean('rt_leavetimes_2016_I_DB.txt')\n",
    "#This line above kill the kernel because it dried all the resources. So, I bash again.\n",
    "#awk -F\";\" 'BEGIN{OFS=\",\";} { print $2,$3,$4,$5,$6,$8,$9,$15 >> \"2016.csv\"}' ../rt_leavetimes_2016_I_DB.txt\n",
    "# This line above drop all the useless columns. Next step: date time, drop suppressed and rename.\n",
    "# This line shorten the time 00:00:00:\n",
    "# awk -F, -vOFS=, 'NR>1{$1=substr($1,1,9)} { print $0 >> \"2016t.csv\" }' 2016.csv\n",
    "# This line will drop suppressed flaged\n",
    "#  grep ',$' 2016t.csv >> 2016s.csv (Explain: any line doesn't end with ,$ means there is something in that column)\n",
    "# use this one to keep header: awk -F\",\" -vOFS=\",\" 'NR==1 || (NR>1 && $8==\"\")' t >>t.csv\n",
    "# This line above has a flaw that it remove my header too.\n",
    "# remove last column\n",
    "# awk -F\",\" 'BEGIN{OFS=\",\";} NF{NF-=1};1' <2016s.csv >>2016r.csv\n",
    "# insert header.\n",
    "#  sed -i '1 i\\dayofservice,tripid,progrnumber,stopid,plannedtime,actual_arr,actual_dep\\n' 2016r.csv\n",
    "# It takes quite a while which makes me worry either it's destroying, or it need to move all the location backward which is time\n",
    "# consuming!\n",
    "# Ok, don't do the \\n thing, it add an empty line ffs.\n",
    "# this line remove empty rows: sed -i '/^$/d' 2016r.csv &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@timeit\n",
    "def createLeavetime(routeid,bigFile):\n",
    "    '''Extract leavetime table base on different routeids.'''\n",
    "    path = 'Test/tripids/'\n",
    "    #from numpy import genfromtxt\n",
    "    #my_data = genfromtxt('my_file.csv', delimiter=',')\n",
    "    tripids = np.genfromtxt(path+routeid)\n",
    "    #print(tripids)\n",
    "    temp = pd.DataFrame()\n",
    "    for chunk in pd.read_csv(bigFile, chunksize=10000):\n",
    "        for trip in tripids:\n",
    "            temp = pd.concat([temp,chunk.loc[chunk['tripid'] == trip]])\n",
    "    temp.to_csv('separated/'+routeid+'.csv',index=False)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for file in os.listdir('Test/tripids/'):\n",
    "    createLeavetime(file,'2016leavetimes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still too slow.... Bash time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreparation(df):\n",
    "    '''All the data preparation will be done by calling this function.'''\n",
    "    \n",
    "    dfw = addWeather(df)\n",
    "    \n",
    "    dfws = addStartTime(dfw)\n",
    "    \n",
    "    #Get rid of negative ones\n",
    "    dfws = dfws.loc[dfws.tripTravelTime >= 0]\n",
    "    \n",
    "    #add distance as a feature\n",
    "    stoptime = pd.read_csv('stop_times.txt')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWeather(data):\n",
    "    '''A function that merge weather information into original df.'''\n",
    "    \n",
    "    weather = pd.read_csv('CleanedWeather2016_17C.csv',index_col=0)\n",
    "    \n",
    "    data.dayofservice = data.dayofservice.astype('datetime64[ns]')\n",
    "    data['datetime'] = data.dayofservice + pd.to_timedelta(data.actual_arr,unit='s')\n",
    "    data['weekday'] = data.dayofservice.dt.dayofweek\n",
    "    data = data.sort_values('datetime')\n",
    "    #data = data.reset_index()\n",
    "    data[['tripid','progrnumber']] = data[['tripid','progrnumber']].astype('int')\n",
    "    df = pd.merge_asof(data,weather,on='datetime',tolerance=pd.Timedelta('1h'))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addStartTime(df):\n",
    "    '''This function will take a dataframe, extract the start time of each trip then append it to  each row.'''\n",
    "    \n",
    "    startTime = df.loc[df.progrnumber == 1]\n",
    "    result = pd.merge(df,startTime,on=['dayofservice','tripid'])\n",
    "    result['tripTravelTime'] = result.actual_arr - result.tripStart \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
